{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cf209b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cec67be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_nodes': 169343, 'num_edges': 1166243, 'feature_dim': 128, 'csum_features': 444011, 'csum_labels': 3501834, 'csum_train': 7744621894, 'csum_test': 2503057778, 'csum_offsets': 99706604203, 'csum_edges': 98781606055, 'num_classes': 40}\n",
      "[0, 43580, 87187, 129587, 169343]\n"
     ]
    }
   ],
   "source": [
    "graph_name = \"ogbn-arxiv\"\n",
    "TARGET_DIR = \"/home/ubuntu/data/\" + graph_name\n",
    "cache_size_in_GB = \"1\"\n",
    "with open(TARGET_DIR + \"/meta.txt\",'r') as fp:\n",
    "    lines = fp.readlines()\n",
    "meta = {}\n",
    "for line in lines:\n",
    "    k, v = line.split(\"=\")\n",
    "    meta[k] = int(v)\n",
    "\n",
    "with open(TARGET_DIR + \"/partition_offsets.txt\", 'r') as fp:\n",
    "    lines = fp.readlines()\n",
    "partition_offsets = lines[0].split(\",\")    \n",
    "partition_offsets = [int(i) for i in partition_offsets]\n",
    "print(meta)\n",
    "print(partition_offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c1273dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_size = \"2MB\"\n",
    "num_nodes = meta['num_nodes']\n",
    "if cache_size[-2:] == \"GB\":\n",
    "    size_in_bytes = (1024 ** 3) * int(cache_size[:-2])\n",
    "if cache_size[-2:] == \"MB\":\n",
    "    size_in_bytes = (1024 ** 2) * int(cache_size[:-2])\n",
    "\n",
    "percentage_of_nodes_to_cache = size_in_bytes/(meta['num_nodes'] * meta['feature_dim'] *  32)\n",
    "percentage_of_nodes_to_cache = min(1, percentage_of_nodes_to_cache)\n",
    "nodes_to_cache = int(percentage_of_nodes_to_cache * num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b283129",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsize = meta['feature_dim']\n",
    "import numpy as np\n",
    "num_partitions = 4\n",
    "ordered_partition_nodes = []\n",
    "for partition in range(num_partitions):\n",
    "    ordered_partition_nodes.append(\\\n",
    "            (torch.arange(partition_offsets[partition],partition_offsets[partition + 1])))    \n",
    "out_degree = torch.from_numpy(np.fromfile(TARGET_DIR + \"out_degrees.bin\",dtype = np.int32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8acd3f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[512, 87187, 129587, 169343], [43580, 44092, 129587, 169343], [43580, 87187, 87699, 169343], [43580, 87187, 129587, 130099]]\n"
     ]
    }
   ],
   "source": [
    "# Create order book foook\n",
    "orderbook = []\n",
    "for curr_partition in range(num_partitions):\n",
    "    global_nodes_not_in_partition = []\n",
    "    local_ordering = []\n",
    "    nodes_to_cache_for_partition = nodes_to_cache\n",
    "    for i in range(num_partitions):\n",
    "        if (i == curr_partition):\n",
    "            global_nodes_in_partition = ordered_partition_nodes[i]\n",
    "        else:\n",
    "            global_nodes_not_in_partition.append(ordered_partition_nodes[i])\n",
    "        local_ordering.append(partition_offsets[i + 1])\n",
    "    num_nodes_from_self =  min(nodes_to_cache, global_nodes_in_partition.shape[0])\n",
    "    nodes_to_cache_for_partition -= num_nodes_from_self\n",
    "    local_ordering[curr_partition] = partition_offsets[curr_partition] + \\\n",
    "                                                    num_nodes_from_self\n",
    "    if(nodes_to_cache_for_partition == 0):\n",
    "        orderbook.append(local_ordering)\n",
    "        continue\n",
    "    \n",
    "    global_nodes_not_partition = torch.cat(global_nodes_not_in_partition)\n",
    "    not_in_partition_degree = out_degree[global_nodes_not_partition]\n",
    "    values, indices = torch.sort(not_in_partition_degree)\n",
    "    global_nodes_not_in_partition_cached = indices[:nodes_to_cache_for_partition]\n",
    "    for i in range(num_partitions):\n",
    "        if i == curr_partition:\n",
    "            continue\n",
    "        selected =  (global_nodes_not_in_partition_cached >= partition_offsets[i] ) \\\n",
    "            & (global_nodes_not_in_partition_cached < partition_offsets[i + 1])\n",
    "        local_ordering[i] = partition_offsets[i] + global_nodes_not_in_partition_cached[selected].shape[0]   \n",
    "    orderbook.append(local_ordering)\n",
    "    \n",
    "print(orderbook)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1294767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{TARGET_DIR}/order_book_{cache_size}.txt\", 'w') as fp:\n",
    "    for p_offsets in orderbook:\n",
    "        str_offsets = [str(p) for p in p_offsets]\n",
    "        str_offsets = \",\".join(str_offsets)\n",
    "        fp.write(f\"{str_offsets}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291dcb88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
